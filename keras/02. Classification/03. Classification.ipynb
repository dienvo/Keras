{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/home/jackdaniel/Documents/learnig skill/keras/02. Classification/pima-indians-diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number_pregnant</th>\n",
       "      <th>Glucose_concentration</th>\n",
       "      <th>Blood_pressure</th>\n",
       "      <th>Triceps</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Pedigree</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class</th>\n",
       "      <th>Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.743719</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500745</td>\n",
       "      <td>0.234415</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.427136</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.292929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.396423</td>\n",
       "      <td>0.116567</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>0.919598</td>\n",
       "      <td>0.524590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347243</td>\n",
       "      <td>0.253629</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.447236</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.232323</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.418778</td>\n",
       "      <td>0.038002</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.688442</td>\n",
       "      <td>0.327869</td>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.198582</td>\n",
       "      <td>0.642325</td>\n",
       "      <td>0.943638</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>0.507538</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.212766</td>\n",
       "      <td>0.490313</td>\n",
       "      <td>0.039710</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>0.613065</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.548435</td>\n",
       "      <td>0.111870</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>0.608040</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.232323</td>\n",
       "      <td>0.132388</td>\n",
       "      <td>0.390462</td>\n",
       "      <td>0.071307</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>0.633166</td>\n",
       "      <td>0.491803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.448584</td>\n",
       "      <td>0.115713</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>0.467337</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.313131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.453055</td>\n",
       "      <td>0.101196</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Number_pregnant  Glucose_concentration  Blood_pressure   Triceps  \\\n",
       "0                  6               0.743719        0.590164  0.353535   \n",
       "1                  1               0.427136        0.540984  0.292929   \n",
       "2                  8               0.919598        0.524590  0.000000   \n",
       "3                  1               0.447236        0.540984  0.232323   \n",
       "4                  0               0.688442        0.327869  0.353535   \n",
       "..               ...                    ...             ...       ...   \n",
       "763               10               0.507538        0.622951  0.484848   \n",
       "764                2               0.613065        0.573770  0.272727   \n",
       "765                5               0.608040        0.590164  0.232323   \n",
       "766                1               0.633166        0.491803  0.000000   \n",
       "767                1               0.467337        0.573770  0.313131   \n",
       "\n",
       "      Insulin       BMI  Pedigree  Age  Class Group  \n",
       "0    0.000000  0.500745  0.234415   50      1     B  \n",
       "1    0.000000  0.396423  0.116567   31      0     C  \n",
       "2    0.000000  0.347243  0.253629   32      1     B  \n",
       "3    0.111111  0.418778  0.038002   21      0     B  \n",
       "4    0.198582  0.642325  0.943638   33      1     C  \n",
       "..        ...       ...       ...  ...    ...   ...  \n",
       "763  0.212766  0.490313  0.039710   63      0     B  \n",
       "764  0.000000  0.548435  0.111870   27      0     A  \n",
       "765  0.132388  0.390462  0.071307   30      0     C  \n",
       "766  0.000000  0.448584  0.115713   47      1     C  \n",
       "767  0.000000  0.453055  0.101196   23      0     A  \n",
       "\n",
       "[768 rows x 10 columns]"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:,0:8].values\n",
    "y=df[\"Class\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding layers for Nueral Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first hideden layer\n",
    "\n",
    "model.add(Dense(20,activation=\"relu\",kernel_initializer=\"normal\",input_dim=8))\n",
    "\n",
    "#second hideden layer\n",
    "\n",
    "model.add(Dense(20,activation=\"relu\",kernel_initializer=\"normal\"))\n",
    "\n",
    "#third hideden layer\n",
    "\n",
    "model.add(Dense(20,activation=\"relu\",kernel_initializer=\"normal\"))\n",
    "\n",
    "#output layer\n",
    "\n",
    "model.add(Dense(1,activation=\"sigmoid\",kernel_initializer=\"normal\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss=\"binary_crossentropy\",metrics=[\"accuracy\"],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 537 samples, validate on 231 samples\n",
      "Epoch 1/100\n",
      "537/537 [==============================] - 1s 3ms/step - loss: 0.6864 - accuracy: 0.6480 - val_loss: 0.6751 - val_accuracy: 0.6494\n",
      "Epoch 2/100\n",
      "537/537 [==============================] - 0s 750us/step - loss: 0.6683 - accuracy: 0.6518 - val_loss: 0.6635 - val_accuracy: 0.6494\n",
      "Epoch 3/100\n",
      "537/537 [==============================] - 0s 719us/step - loss: 0.6638 - accuracy: 0.6518 - val_loss: 0.6610 - val_accuracy: 0.6494\n",
      "Epoch 4/100\n",
      "537/537 [==============================] - 0s 667us/step - loss: 0.6592 - accuracy: 0.6518 - val_loss: 0.6573 - val_accuracy: 0.6494\n",
      "Epoch 5/100\n",
      "537/537 [==============================] - 0s 734us/step - loss: 0.6558 - accuracy: 0.6518 - val_loss: 0.6561 - val_accuracy: 0.6494\n",
      "Epoch 6/100\n",
      "537/537 [==============================] - 0s 749us/step - loss: 0.6508 - accuracy: 0.6518 - val_loss: 0.6504 - val_accuracy: 0.6494\n",
      "Epoch 7/100\n",
      "537/537 [==============================] - 0s 713us/step - loss: 0.6457 - accuracy: 0.6518 - val_loss: 0.6461 - val_accuracy: 0.6494\n",
      "Epoch 8/100\n",
      "537/537 [==============================] - 0s 751us/step - loss: 0.6424 - accuracy: 0.6518 - val_loss: 0.6438 - val_accuracy: 0.6494\n",
      "Epoch 9/100\n",
      "537/537 [==============================] - 1s 936us/step - loss: 0.6373 - accuracy: 0.6518 - val_loss: 0.6417 - val_accuracy: 0.6494\n",
      "Epoch 10/100\n",
      "537/537 [==============================] - 0s 919us/step - loss: 0.6341 - accuracy: 0.6518 - val_loss: 0.6421 - val_accuracy: 0.6494\n",
      "Epoch 11/100\n",
      "537/537 [==============================] - 0s 590us/step - loss: 0.6379 - accuracy: 0.6518 - val_loss: 0.6375 - val_accuracy: 0.6494\n",
      "Epoch 12/100\n",
      "537/537 [==============================] - 0s 470us/step - loss: 0.6294 - accuracy: 0.6518 - val_loss: 0.6356 - val_accuracy: 0.6494\n",
      "Epoch 13/100\n",
      "537/537 [==============================] - 0s 568us/step - loss: 0.6292 - accuracy: 0.6536 - val_loss: 0.6328 - val_accuracy: 0.6494\n",
      "Epoch 14/100\n",
      "537/537 [==============================] - 0s 535us/step - loss: 0.6259 - accuracy: 0.6536 - val_loss: 0.6362 - val_accuracy: 0.6623\n",
      "Epoch 15/100\n",
      "537/537 [==============================] - 0s 601us/step - loss: 0.6220 - accuracy: 0.6499 - val_loss: 0.6312 - val_accuracy: 0.6364\n",
      "Epoch 16/100\n",
      "537/537 [==============================] - 0s 597us/step - loss: 0.6188 - accuracy: 0.6425 - val_loss: 0.6306 - val_accuracy: 0.6494\n",
      "Epoch 17/100\n",
      "537/537 [==============================] - 0s 617us/step - loss: 0.6180 - accuracy: 0.6518 - val_loss: 0.6241 - val_accuracy: 0.6364\n",
      "Epoch 18/100\n",
      "537/537 [==============================] - 0s 497us/step - loss: 0.6151 - accuracy: 0.6555 - val_loss: 0.6172 - val_accuracy: 0.6450\n",
      "Epoch 19/100\n",
      "537/537 [==============================] - 0s 473us/step - loss: 0.6142 - accuracy: 0.6797 - val_loss: 0.6156 - val_accuracy: 0.6450\n",
      "Epoch 20/100\n",
      "537/537 [==============================] - 0s 577us/step - loss: 0.6115 - accuracy: 0.6816 - val_loss: 0.6188 - val_accuracy: 0.6797\n",
      "Epoch 21/100\n",
      "537/537 [==============================] - 0s 459us/step - loss: 0.6051 - accuracy: 0.6760 - val_loss: 0.6067 - val_accuracy: 0.6623\n",
      "Epoch 22/100\n",
      "537/537 [==============================] - 0s 476us/step - loss: 0.6022 - accuracy: 0.6816 - val_loss: 0.6037 - val_accuracy: 0.6710\n",
      "Epoch 23/100\n",
      "537/537 [==============================] - 0s 469us/step - loss: 0.5977 - accuracy: 0.6797 - val_loss: 0.6003 - val_accuracy: 0.6753\n",
      "Epoch 24/100\n",
      "537/537 [==============================] - 0s 463us/step - loss: 0.5922 - accuracy: 0.6872 - val_loss: 0.5876 - val_accuracy: 0.6840\n",
      "Epoch 25/100\n",
      "537/537 [==============================] - 0s 581us/step - loss: 0.5894 - accuracy: 0.6629 - val_loss: 0.5906 - val_accuracy: 0.6840\n",
      "Epoch 26/100\n",
      "537/537 [==============================] - 0s 505us/step - loss: 0.5860 - accuracy: 0.6797 - val_loss: 0.5907 - val_accuracy: 0.6883\n",
      "Epoch 27/100\n",
      "537/537 [==============================] - 0s 555us/step - loss: 0.5780 - accuracy: 0.6704 - val_loss: 0.5637 - val_accuracy: 0.6840\n",
      "Epoch 28/100\n",
      "537/537 [==============================] - 0s 497us/step - loss: 0.5691 - accuracy: 0.6760 - val_loss: 0.5709 - val_accuracy: 0.6753\n",
      "Epoch 29/100\n",
      "537/537 [==============================] - 0s 495us/step - loss: 0.5670 - accuracy: 0.6723 - val_loss: 0.5598 - val_accuracy: 0.7100\n",
      "Epoch 30/100\n",
      "537/537 [==============================] - 0s 579us/step - loss: 0.5611 - accuracy: 0.6797 - val_loss: 0.5496 - val_accuracy: 0.7056\n",
      "Epoch 31/100\n",
      "537/537 [==============================] - 0s 542us/step - loss: 0.5535 - accuracy: 0.7002 - val_loss: 0.5423 - val_accuracy: 0.7186\n",
      "Epoch 32/100\n",
      "537/537 [==============================] - 0s 551us/step - loss: 0.5761 - accuracy: 0.6723 - val_loss: 0.5794 - val_accuracy: 0.7013\n",
      "Epoch 33/100\n",
      "537/537 [==============================] - 0s 606us/step - loss: 0.5532 - accuracy: 0.6834 - val_loss: 0.5420 - val_accuracy: 0.7100\n",
      "Epoch 34/100\n",
      "537/537 [==============================] - 0s 704us/step - loss: 0.5420 - accuracy: 0.7058 - val_loss: 0.5414 - val_accuracy: 0.7143\n",
      "Epoch 35/100\n",
      "537/537 [==============================] - 1s 1ms/step - loss: 0.5419 - accuracy: 0.6872 - val_loss: 0.5330 - val_accuracy: 0.7143\n",
      "Epoch 36/100\n",
      "537/537 [==============================] - 0s 836us/step - loss: 0.5550 - accuracy: 0.7114 - val_loss: 0.5311 - val_accuracy: 0.7273\n",
      "Epoch 37/100\n",
      "537/537 [==============================] - 0s 929us/step - loss: 0.5362 - accuracy: 0.7039 - val_loss: 0.5272 - val_accuracy: 0.7403\n",
      "Epoch 38/100\n",
      "537/537 [==============================] - 0s 820us/step - loss: 0.5380 - accuracy: 0.7188 - val_loss: 0.5287 - val_accuracy: 0.7403\n",
      "Epoch 39/100\n",
      "537/537 [==============================] - 0s 805us/step - loss: 0.5271 - accuracy: 0.7281 - val_loss: 0.5337 - val_accuracy: 0.7229\n",
      "Epoch 40/100\n",
      "537/537 [==============================] - 1s 1ms/step - loss: 0.5429 - accuracy: 0.7095 - val_loss: 0.5293 - val_accuracy: 0.7359\n",
      "Epoch 41/100\n",
      "537/537 [==============================] - 1s 981us/step - loss: 0.5250 - accuracy: 0.7151 - val_loss: 0.5348 - val_accuracy: 0.7229\n",
      "Epoch 42/100\n",
      "537/537 [==============================] - 0s 843us/step - loss: 0.5359 - accuracy: 0.7020 - val_loss: 0.5179 - val_accuracy: 0.7359\n",
      "Epoch 43/100\n",
      "537/537 [==============================] - 0s 634us/step - loss: 0.5193 - accuracy: 0.7263 - val_loss: 0.5159 - val_accuracy: 0.7489\n",
      "Epoch 44/100\n",
      "537/537 [==============================] - 0s 492us/step - loss: 0.5212 - accuracy: 0.7114 - val_loss: 0.5152 - val_accuracy: 0.7403\n",
      "Epoch 45/100\n",
      "537/537 [==============================] - 0s 734us/step - loss: 0.5238 - accuracy: 0.7337 - val_loss: 0.5197 - val_accuracy: 0.7403\n",
      "Epoch 46/100\n",
      "537/537 [==============================] - 0s 829us/step - loss: 0.5204 - accuracy: 0.7244 - val_loss: 0.5163 - val_accuracy: 0.7532\n",
      "Epoch 47/100\n",
      "537/537 [==============================] - 0s 757us/step - loss: 0.5177 - accuracy: 0.7263 - val_loss: 0.5146 - val_accuracy: 0.7316\n",
      "Epoch 48/100\n",
      "537/537 [==============================] - 0s 497us/step - loss: 0.5176 - accuracy: 0.7114 - val_loss: 0.5122 - val_accuracy: 0.7359\n",
      "Epoch 49/100\n",
      "537/537 [==============================] - 0s 511us/step - loss: 0.5178 - accuracy: 0.7225 - val_loss: 0.5752 - val_accuracy: 0.6710\n",
      "Epoch 50/100\n",
      "537/537 [==============================] - 0s 631us/step - loss: 0.5329 - accuracy: 0.7132 - val_loss: 0.5321 - val_accuracy: 0.7186\n",
      "Epoch 51/100\n",
      "537/537 [==============================] - 0s 636us/step - loss: 0.5150 - accuracy: 0.7374 - val_loss: 0.5147 - val_accuracy: 0.7446\n",
      "Epoch 52/100\n",
      "537/537 [==============================] - 0s 578us/step - loss: 0.5131 - accuracy: 0.7356 - val_loss: 0.5075 - val_accuracy: 0.7532\n",
      "Epoch 53/100\n",
      "537/537 [==============================] - 0s 663us/step - loss: 0.5048 - accuracy: 0.7393 - val_loss: 0.5152 - val_accuracy: 0.7532\n",
      "Epoch 54/100\n",
      "537/537 [==============================] - 0s 616us/step - loss: 0.5486 - accuracy: 0.6909 - val_loss: 0.5150 - val_accuracy: 0.7446\n",
      "Epoch 55/100\n",
      "537/537 [==============================] - 0s 458us/step - loss: 0.5045 - accuracy: 0.7467 - val_loss: 0.5068 - val_accuracy: 0.7446\n",
      "Epoch 56/100\n",
      "537/537 [==============================] - 0s 565us/step - loss: 0.5040 - accuracy: 0.7467 - val_loss: 0.5054 - val_accuracy: 0.7619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "537/537 [==============================] - 0s 494us/step - loss: 0.5042 - accuracy: 0.7393 - val_loss: 0.5210 - val_accuracy: 0.7446\n",
      "Epoch 58/100\n",
      "537/537 [==============================] - 0s 461us/step - loss: 0.5094 - accuracy: 0.7281 - val_loss: 0.5023 - val_accuracy: 0.7532\n",
      "Epoch 59/100\n",
      "537/537 [==============================] - 0s 498us/step - loss: 0.4989 - accuracy: 0.7561 - val_loss: 0.5091 - val_accuracy: 0.7359\n",
      "Epoch 60/100\n",
      "537/537 [==============================] - 0s 519us/step - loss: 0.5063 - accuracy: 0.7337 - val_loss: 0.5112 - val_accuracy: 0.7792\n",
      "Epoch 61/100\n",
      "537/537 [==============================] - 0s 513us/step - loss: 0.5266 - accuracy: 0.7430 - val_loss: 0.5262 - val_accuracy: 0.7489\n",
      "Epoch 62/100\n",
      "537/537 [==============================] - 0s 527us/step - loss: 0.4934 - accuracy: 0.7598 - val_loss: 0.5227 - val_accuracy: 0.7273\n",
      "Epoch 63/100\n",
      "537/537 [==============================] - 0s 464us/step - loss: 0.4915 - accuracy: 0.7486 - val_loss: 0.4981 - val_accuracy: 0.7446\n",
      "Epoch 64/100\n",
      "537/537 [==============================] - 0s 467us/step - loss: 0.4934 - accuracy: 0.7467 - val_loss: 0.5043 - val_accuracy: 0.7359\n",
      "Epoch 65/100\n",
      "537/537 [==============================] - 0s 460us/step - loss: 0.4967 - accuracy: 0.7486 - val_loss: 0.4979 - val_accuracy: 0.7576\n",
      "Epoch 66/100\n",
      "537/537 [==============================] - 0s 520us/step - loss: 0.4911 - accuracy: 0.7598 - val_loss: 0.5142 - val_accuracy: 0.7922\n",
      "Epoch 67/100\n",
      "537/537 [==============================] - 0s 541us/step - loss: 0.4967 - accuracy: 0.7486 - val_loss: 0.5134 - val_accuracy: 0.7359\n",
      "Epoch 68/100\n",
      "537/537 [==============================] - 0s 535us/step - loss: 0.4896 - accuracy: 0.7505 - val_loss: 0.5402 - val_accuracy: 0.7532\n",
      "Epoch 69/100\n",
      "537/537 [==============================] - 0s 556us/step - loss: 0.5030 - accuracy: 0.7318 - val_loss: 0.4953 - val_accuracy: 0.7446\n",
      "Epoch 70/100\n",
      "537/537 [==============================] - 0s 486us/step - loss: 0.4823 - accuracy: 0.7672 - val_loss: 0.4964 - val_accuracy: 0.7403\n",
      "Epoch 71/100\n",
      "537/537 [==============================] - 0s 456us/step - loss: 0.4907 - accuracy: 0.7337 - val_loss: 0.4893 - val_accuracy: 0.7619\n",
      "Epoch 72/100\n",
      "537/537 [==============================] - 0s 519us/step - loss: 0.5045 - accuracy: 0.7318 - val_loss: 0.4857 - val_accuracy: 0.7662\n",
      "Epoch 73/100\n",
      "537/537 [==============================] - 0s 503us/step - loss: 0.4844 - accuracy: 0.7523 - val_loss: 0.5041 - val_accuracy: 0.7316\n",
      "Epoch 74/100\n",
      "537/537 [==============================] - 0s 605us/step - loss: 0.5103 - accuracy: 0.7505 - val_loss: 0.4837 - val_accuracy: 0.7879\n",
      "Epoch 75/100\n",
      "537/537 [==============================] - 0s 489us/step - loss: 0.5116 - accuracy: 0.7207 - val_loss: 0.4911 - val_accuracy: 0.7922\n",
      "Epoch 76/100\n",
      "537/537 [==============================] - 0s 493us/step - loss: 0.4922 - accuracy: 0.7430 - val_loss: 0.4901 - val_accuracy: 0.7879\n",
      "Epoch 77/100\n",
      "537/537 [==============================] - 0s 538us/step - loss: 0.4847 - accuracy: 0.7654 - val_loss: 0.4806 - val_accuracy: 0.7792\n",
      "Epoch 78/100\n",
      "537/537 [==============================] - 0s 489us/step - loss: 0.4775 - accuracy: 0.7654 - val_loss: 0.4773 - val_accuracy: 0.7965\n",
      "Epoch 79/100\n",
      "537/537 [==============================] - 0s 509us/step - loss: 0.4782 - accuracy: 0.7635 - val_loss: 0.5213 - val_accuracy: 0.7532\n",
      "Epoch 80/100\n",
      "537/537 [==============================] - 0s 453us/step - loss: 0.5019 - accuracy: 0.7430 - val_loss: 0.4845 - val_accuracy: 0.8052\n",
      "Epoch 81/100\n",
      "537/537 [==============================] - 0s 535us/step - loss: 0.4905 - accuracy: 0.7579 - val_loss: 0.4840 - val_accuracy: 0.7662\n",
      "Epoch 82/100\n",
      "537/537 [==============================] - 0s 500us/step - loss: 0.4749 - accuracy: 0.7654 - val_loss: 0.4751 - val_accuracy: 0.7965\n",
      "Epoch 83/100\n",
      "537/537 [==============================] - 0s 538us/step - loss: 0.4758 - accuracy: 0.7672 - val_loss: 0.4719 - val_accuracy: 0.8052\n",
      "Epoch 84/100\n",
      "537/537 [==============================] - 0s 461us/step - loss: 0.4899 - accuracy: 0.7542 - val_loss: 0.4814 - val_accuracy: 0.7532\n",
      "Epoch 85/100\n",
      "537/537 [==============================] - 0s 493us/step - loss: 0.4781 - accuracy: 0.7709 - val_loss: 0.4780 - val_accuracy: 0.7619\n",
      "Epoch 86/100\n",
      "537/537 [==============================] - 0s 464us/step - loss: 0.4771 - accuracy: 0.7691 - val_loss: 0.4728 - val_accuracy: 0.8052\n",
      "Epoch 87/100\n",
      "537/537 [==============================] - 0s 564us/step - loss: 0.4906 - accuracy: 0.7616 - val_loss: 0.4923 - val_accuracy: 0.7359\n",
      "Epoch 88/100\n",
      "537/537 [==============================] - 0s 490us/step - loss: 0.4791 - accuracy: 0.7709 - val_loss: 0.4726 - val_accuracy: 0.8052\n",
      "Epoch 89/100\n",
      "537/537 [==============================] - 0s 469us/step - loss: 0.4625 - accuracy: 0.7579 - val_loss: 0.4770 - val_accuracy: 0.7922\n",
      "Epoch 90/100\n",
      "537/537 [==============================] - 0s 471us/step - loss: 0.4709 - accuracy: 0.7635 - val_loss: 0.4773 - val_accuracy: 0.8052\n",
      "Epoch 91/100\n",
      "537/537 [==============================] - 0s 542us/step - loss: 0.4744 - accuracy: 0.7691 - val_loss: 0.4861 - val_accuracy: 0.7489\n",
      "Epoch 92/100\n",
      "537/537 [==============================] - 0s 501us/step - loss: 0.4694 - accuracy: 0.7635 - val_loss: 0.4685 - val_accuracy: 0.7922\n",
      "Epoch 93/100\n",
      "537/537 [==============================] - 0s 515us/step - loss: 0.4752 - accuracy: 0.7709 - val_loss: 0.4681 - val_accuracy: 0.8009\n",
      "Epoch 94/100\n",
      "537/537 [==============================] - 0s 484us/step - loss: 0.4913 - accuracy: 0.7579 - val_loss: 0.4705 - val_accuracy: 0.8095\n",
      "Epoch 95/100\n",
      "537/537 [==============================] - 0s 509us/step - loss: 0.5023 - accuracy: 0.7356 - val_loss: 0.5073 - val_accuracy: 0.7316\n",
      "Epoch 96/100\n",
      "537/537 [==============================] - 0s 516us/step - loss: 0.4697 - accuracy: 0.7672 - val_loss: 0.4685 - val_accuracy: 0.8009\n",
      "Epoch 97/100\n",
      "537/537 [==============================] - 0s 459us/step - loss: 0.4649 - accuracy: 0.7728 - val_loss: 0.4798 - val_accuracy: 0.7922\n",
      "Epoch 98/100\n",
      "537/537 [==============================] - 0s 481us/step - loss: 0.4751 - accuracy: 0.7635 - val_loss: 0.4714 - val_accuracy: 0.7922\n",
      "Epoch 99/100\n",
      "537/537 [==============================] - 0s 462us/step - loss: 0.4748 - accuracy: 0.7709 - val_loss: 0.4737 - val_accuracy: 0.8009\n",
      "Epoch 100/100\n",
      "537/537 [==============================] - 0s 470us/step - loss: 0.4678 - accuracy: 0.7635 - val_loss: 0.4731 - val_accuracy: 0.7835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7ff6225ed828>"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(  x=x_train,\n",
    "            y=y_train,\n",
    "            batch_size=10,\n",
    "            epochs=100,\n",
    "            validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 78.21%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=df.iloc[0:1,0:8].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "prd=model.predict(input)\n",
    "if prd>0.5:\n",
    "    prd=1\n",
    "else:\n",
    "    prd=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "for i in prediction:\n",
    "    \n",
    "    if i>0.5:\n",
    "        results.append(1)\n",
    "    else:\n",
    "        results.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1]"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of precitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[127,  23],\n",
       "       [ 27,  54]])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.22077922077922"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "183/231*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"first_saved_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Neural Networks model to JSON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json=model.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create json file to write the model\n",
    "\n",
    "with open(\"/home/jackdaniel/Documents/learnig skill/keras/02. Classification/json_model/model.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "#save the model weights in model.h5 file    \n",
    "model.save_weights(\"/home/jackdaniel/Documents/learnig skill/keras/02. Classification/json_model/second_saved_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the model from the json file\n",
    "\n",
    "json_file=open(\"/home/jackdaniel/Documents/learnig skill/keras/02. Classification/json_model/model.json\",\"r\")\n",
    "json_read=json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(json_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the weights in the model.h5 file\n",
    "\n",
    "loaded_model.load_weights(\"/home/jackdaniel/Documents/learnig skill/keras/02. Classification/json_model/second_saved_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "#important to compile the loaded model before it is used \n",
    "\n",
    "loaded_model.compile(optimizer='adam',loss=\"binary_crossentropy\",metrics=[\"accuracy\"],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 78.21%\n"
     ]
    }
   ],
   "source": [
    "#check the accuracy of the loaded model\n",
    "\n",
    "scores = loaded_model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Neural Networks model to YAML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_yaml=model.to_yaml()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create yaml file to write the model\n",
    "\n",
    "with open(\"/home/jackdaniel/Documents/learnig skill/keras/02. Classification/yaml_model/model.yaml\",\"w\") as json_file:\n",
    "    json_file.write(model_yaml)\n",
    "\n",
    "#save the model weights in model.h5 file    \n",
    "model.save_weights(\"/home/jackdaniel/Documents/learnig skill/keras/02. Classification/yaml_model/third_saved_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the model from the yaml file\n",
    "\n",
    "yaml_file=open(\"/home/jackdaniel/Documents/learnig skill/keras/02. Classification/yaml_model/model.yaml\",\"r\")\n",
    "yaml_read=yaml_file.read()\n",
    "yaml_file.close()\n",
    "loaded_model = model_from_yaml(yaml_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the weights in the model.h5 file\n",
    "\n",
    "loaded_model.load_weights(\"/home/jackdaniel/Documents/learnig skill/keras/02. Classification/yaml_model/third_saved_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "#important to compile the loaded model before it is used \n",
    "\n",
    "loaded_model.compile(optimizer='adam',loss=\"binary_crossentropy\",metrics=[\"accuracy\"],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 78.21%\n"
     ]
    }
   ],
   "source": [
    "#check the accuracy of the loaded model\n",
    "\n",
    "scores = loaded_model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
